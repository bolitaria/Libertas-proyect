# üïäÔ∏è libertas-project-fetcher ‚Äî main_v3.py (B√∫squeda paralelizada)

Descripci√≥n
-----------
Script principal: `fetcher/main_v3.py`

Versi√≥n optimizada con:
- Descubrimiento ilimitado de datasets
- B√∫squeda y conteo de archivos por dataset sin descargar (--query-files)
- B√∫squeda y descarga paralelizadas (--workers, --page-workers)
- Cach√© en memoria de p√°ginas para acelerar reconsultas
- Pool de conexiones, timeouts reducidos y retries inteligentes
- Trazabilidad/metadata en `/data/downloads/metadata/traces`

Instalaci√≥n / Entorno
---------------------
Ejecutar dentro del entorno del proyecto (WSL/Ubuntu):

- Aseg√∫rate de tener dependencias en venv y Docker si corresponde.
- Rutas de output por defecto: `/data/downloads`, `/data/logs`.

Comandos principales
--------------------
- Descubrir datasets disponibles (r√°pido, paralelo):
  ```bash
  python fetcher/main_v3.py --discover
  ```

- Consultar cu√°ntos archivos hay por cada dataset (no descarga, recomendado):
  ```bash
  python fetcher/main_v3.py --query-files
  ```

- Consultar (r√°pido) con m√°s concurrencia:
  ```bash
  python fetcher/main_v3.py --query-files --workers 12 --page-workers 6
  ```

- Descargar un dataset (auto-detecci√≥n del √∫ltimo page):
  ```bash
  python fetcher/main_v3.py --page-ranges "1" --limit 100 --delay 0.5
  ```

- Descargar m√∫ltiples rangos expl√≠citos:
  ```bash
  python fetcher/main_v3.py --page-ranges "1 2:5 3:10" --limit 200
  ```

- Procesar TODOS los datasets (sin l√≠mite):
  ```bash
  python fetcher/main_v3.py --all --limit 500
  ```

Par√°metros √∫tiles
-----------------
- --page-ranges "DS[:start] DS[:start]"  
  Ejemplos aceptados: `"1"`, `"1:1"`, `"1:5"`, `"1 2:5 3:10"`

- --query-files  : cuenta archivos por dataset sin descargarlos  
- --discover     : lista datasets disponibles  
- --workers N    : threads para datasets (recomendado 4‚Äì12)  
- --page-workers N: threads para p√°ginas (recomendado 2‚Äì6)  
- --limit N      : m√°ximo archivos a descargar  
- --delay S      : espera entre descargas (segundos)  
- --stats        : muestra estad√≠sticas de cach√© y descargas  
- --clean        : elimina descargas (use --force para evitar confirmaci√≥n)

Salida y trazas
---------------
- Descargas: `/data/downloads/raw/dataset_<n>/`
- Cache/metadatos: `/data/downloads/metadata/url_cache.json`
- Trazas (JSON): `/data/downloads/metadata/traces/trace_<id>.json`
- Logs: `/data/logs/fetcher_v3_exhaustive.log`

Recomendaciones r√°pidas
-----------------------
1. Ejecutar `--discover` para verificar datasets.  
2. Ejecutar `--query-files` para medir volumen (2‚Äì5 min t√≠picamente).  
3. Probar con `--all --limit 50` o `--page-ranges "1" --limit 10` antes de producci√≥n.  
4. Ajustar `--workers` y `--page-workers` seg√∫n CPU y cortes del servidor (no exceder 16/8).  
5. Monitorizar `/data/logs/` y traces JSON para auditor√≠a.

Ejemplo de flujo recomendado
---------------------------
```bash
# 1) descubrir datasets
python fetcher/main_v3.py --discover

# 2) conocer volumen
python fetcher/main_v3.py --query-files --workers 8 --page-workers 4

# 3) descargar muestra
python fetcher/main_v3.py --all --limit 50 --delay 0.5

# 4) revisar trazas y logs
tail -n 200 /data/logs/fetcher_v3_exhaustive.log
cat /data/downloads/metadata/traces/trace_*.json | jq .
```

Notas t√©cnicas
--------------
- Detecci√≥n de √∫ltima p√°gina: b√∫squeda exponencial + binaria (paralelizada).
- Cach√© en memoria acelera reconsultas durante la misma ejecuci√≥n.
- Mantener delays y l√≠mites razonables para evitar bloquearse del servidor.

Contacto / mantenimiento
------------------------
- Archivo principal: `fetcher/main_v3.py`  
- Actualizaciones: mantener coherencia entre README y las opciones del script.

Versi√≥n
-------
main_v3.py ‚Äî Febrero 2026 (B√∫squeda paralelizada, consulta r√°pida de archivos)